---
title: 小样本数据扩增总结
date: 2021-03-28 16:48:15
tags: 
- 小样本
- 数据扩增
categories: ResearchLife
---

寒假的时候针对小样本扩增这一块内容收集了很多文献，也看了很多文献。第一次有点科研的感觉，在这里做个总结。
![title_pic](https://forlwq.oss-cn-hangzhou.aliyuncs.com/Research/small_samples_augmentation/1.png)

<!--more-->

随着机器学习（特别是深度学习）的发展，它的问题也逐渐凸显出来。深度学习一般需要大量的数据集，才能训练到效果较好的模型。近年来，对小样本的研究越来越多。一方面，不是所有领域都有**充足的样本**用来训练模型，比如医学领域。另一方面，基于大量数据得到的深度学习模型训练也需要**较高的代价**，如设备资源、训练时长等等，若能从少量样本中学习概念知识，能在一定程度减小代价。

按照综述《**Generalizing from a Few Examples: A Survey on Few-Shot Learning**》。先给出**小样本学习（Few-Shot Learning, FSL）**的定义：

> 属于机器学习的一类任务，区别在于FSL用于目标任务的信息较少（训练集数量少）。

综述里对小样本学习从不同角度分成了三个类型：**1. 模型 2. 数据 3. 算法**。我这篇博客想要讨论的**数据扩增**，就属于从**数据**角度来解决小样本学习问题。

而从数据角度而言，又可以分成三种类型：1. 从**训练集**中转换样本；2. 从**弱标签或无标签数据集**中转换样本；3. 从**相似数据集**中转换样本。这张图比较容易理解：

<img src="https://forlwq.oss-cn-hangzhou.aliyuncs.com/Research/small_samples_augmentation/image-20210323095705808.png" alt="数据扩增以解决小样本问题" style="zoom:80%;" />

另外我认为，**数据增强（Data Augmentation）**也可以分成这样两种方法:1. 从**基本图像处理**进行增强，如裁剪、旋转、变化颜色等；2. 从**特征**进行扩增，如使用GAN合成样本、映射到特征空间内增强（SMOTE）、神经风格迁移

> 借鉴了[这篇文章](https://www.jiqizhixin.com/articles/2019-12-04-10)，也是分成了类似的两类，第一类是基于基本图像处理技术，第二类是**基于深度学习**。我觉得也写得很好，但是我感觉第二类这样叫不太准确，SMOTE方法应该是不算深度学习的。

《A survey on Image Data Augmentation for Deep Learning》是关于**图像的数据增强**综述。这篇文章更详细地阐述了相关方法的分类：

> The augmentations listed in this survey are **geometric transformations, color space transformations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, GAN-based augmentation, neural style transfer, and meta-learning schemes**.

接下来列出几篇做样本扩增的文献，主要是从训练集本身来合成新样本。下面四篇是综述中引用的文献：

# Delta-encoder: an effective sample synthesis method for few-shot object recognition（IBM Research AI, NIPS 2018）

基于**自动编码器**，学习能够用于合成**新类别**样本的模型。模型图：

![delta-encoder架构](https://forlwq.oss-cn-hangzhou.aliyuncs.com/Research/small_samples_augmentation/image-20210323110113774.png)

**(a)训练阶段**: $X^s$ 和$Y^s$是来自同一个可见类的随机一对样本; Δ-encoder学习重建得到$\hat{X}^s$。 **(b)样本合成阶段** :$X^s$和$Y^s$是随机已知类中随机的一对样本，$Y^u$是新的未知类中的单个样本；Δ-encoder从新类中生成一个新的示例$\hat{X}^u$。

本文希望学习到不同样本之间的**可迁移的差异性**，然后用到新样本上去。实验也是通过N-way K-shot的方法进行。

训练阶段需要10个epoch达到收敛，每个epoch在Nvidia Tesla K40m GPU上跑20s。（我感觉挺快的？）

# Low-shot visual recognition by shrinking and hallucinating features（Facebook AI Research, CVPR 2017）

和上一篇一样，期望学习到样本间**可迁移的差异性**。即学习到的样本变换信息，可以用到别的类别上去（但是这两种类别也比较相似，如不同种类的鸟。本文通过对每个类别做聚类，判断质心距离的方法评估相似性）。

此外，本文希望学习到一个**生成器**（文中提到是多层感知器），学习到样本间可迁移的差异性用到新类别上去。关于差异性迁移，可以通过下图来理解：

![image-20210323112338424](https://forlwq.oss-cn-hangzhou.aliyuncs.com/Research/small_samples_augmentation/image-20210323112338424.png)

以第一行为例，左边两张图都是小灰鸟，右边两张图都是小蓝鸟，分别属于两个类别。左边小灰鸟一个是以天空为背景，一个是以树叶为背景，模型将学习到这个差异性。这个差异性能够迁移到小蓝鸟上，当我们有以天空为背景的小蓝鸟照片时，通过差异性的迁移，就能得到以树叶为背景的小蓝鸟照片。

PS：我还挺喜欢这个迁移差异性的思想，感觉挺有意思的。不过我感觉“模型可以学习到差异性”这个说法，有点抽象。

# One-Shot Learning of Scene Locations via Feature Trajectory Transfer(CVPR 2016)

从一组图像上学习一个瞬态属性的特征轨迹，将轨迹转移到新的图像上生成某个属性（如晴天、阴天）在不同强度下对应的图像。图像举例：

<img src="https://forlwq.oss-cn-hangzhou.aliyuncs.com/Research/small_samples_augmentation/image-20210323144845585.png" alt="数据集举例" style="zoom:80%;" />

上图中，每一行表示一个照相机采集到的照片。对应的属性为sunny，在不同属性强度下的照片。

本文希望从细粒度数据集中学习知识，然后基于新数据合成样本。文中提到，特征轨迹转移的方法基于两个假设：1. 通过图像的**特征表示**能够**预测其瞬态属性**；2. 这种瞬态属性与特征表示之间的**函数关系**能够建模为**特征空间中的轨迹**。

![特征轨迹转移和合成图解](https://forlwq.oss-cn-hangzhou.aliyuncs.com/Research/small_samples_augmentation/image-20210323145600859.png)

对于新图像，先用计算它**在属性空间中的表示**，得到一个对应的属性向量。迭代所有场景，**对每个属性**都学习到新样本的**特征轨迹转移**。最后，分别沿每个属性对应的转移轨迹预测对应的特征。最终对来自所有场景的预测值进行加权，得到合成图像。

这篇我有点一知半解。看文章的公式，好像就用了一个线性模型来合成新样本。

# Feature Space Transfer for Data Augmentation(CVPR 2018)

同样是**特征轨迹**，这里的是**姿态**变化轨迹。用到**解纠缠**的思想，用两个编码器，将图像的**外观**和**姿态**两种属性分开来了。

![特征空间转换示意图](https://forlwq.oss-cn-hangzhou.aliyuncs.com/Research/small_samples_augmentation/image-20210323150601178.png)

上图所示，不同的图像特征向量，可以映射到外观空间中的同一点，映射到姿态空间中的不同点。

本文的模型结构是下图：

![FATTEN架构](https://forlwq.oss-cn-hangzhou.aliyuncs.com/Research/small_samples_augmentation/image-20210323150827500.png)



# 碎碎念

刚开始写这篇的时候，被老师叫去谈话了。这个突然就变成了我的课题- -

加油吧！这个礼拜先写这么多，之后慢慢补充吧。